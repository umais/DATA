---
title: "GROUP 2 HW4: Insurance - Data 621 Assignment 4"
author: 'GROUP 2 MEMBERS: Banu Boopalan, Gregg Maloy, Alexander Moyse, Umais Siddiqui'
date: "11-12-2024"
output:
  html_document:
    code_folding: hide
    df_print: paged
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    theme: yeti
    highlight: pygments
  pdf_document:
    latex_engine: xelatex
    df_print: tibble
    toc: true
    toc_depth: 2
  word_document:
    toc: true
    toc_depth: '2'
---
<STYLE>
table {
    border: 1px solid black;
}
th {
    background-color: rgb(204, 114, 12);
    color: black;
    font-weight: bold;
    padding: 20px 30px;
}
tr:nth-child(even) {
    background-color: rgb(220,220,220);
}
tr:nth-child(odd) {
    background-color: rgb(184, 174, 174);
    
}
</STYLE>

## Assignment Introduction

In this project, we will analyze the data provided by conducting exploratory data analysis (EDA) and building two different models: a multiple linear regression model and a binary logistic regression model. This is necessary because we have two target variables—TARGET_FLAG, a binary variable indicating whether a crash occurred (1) or not (0), and TARGET_AMT, a continuous variable representing the cost associated with a crash. We will carefully select predictor variables to generate the best-performing models for both targets.

We have read in the two datasets, the training and evaluation datasets, which were provided through GitHub.

Our goal is to analyze 8,000 records of customers from an insurance company. After fitting the models to the training data, we will apply them to the evaluation dataset. We will assess the validity and performance of each model, then report the results to identify the model that best fits the data.

Below is an image showing all the variables and their definitions.

![Variable Definitions](variables.png)



```{r setup}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)
```


```{r setup1 }

library(kableExtra)
library(tidyverse)
library(tidyr)
library(forecast)
library(cowplot)
#install.packages("car")
library(naniar)
library(Seurat)
library(skimr)
library(PerformanceAnalytics)
library(corrplot)
library(mice)
library(ggplot2)
library(reshape2)
library(dplyr)
library(tidyr)
library(MASS)# For stepAIC (Stepwise selection)
library(caret)  # For splitting data and cross-validation
library(leaps)
library(car)
# Load necessary libraries
library(VIM)
library(DataExplorer)
library(scales)
library(e1071) 
library(smotefamily)


insurance_training_data <- read.csv("https://raw.githubusercontent.com/umais/DATA/refs/heads/main/insurance_training_data.csv",stringsAsFactors = F,header=TRUE)

insurance_test_data <- read.csv("https://raw.githubusercontent.com/umais/DATA/refs/heads/main/insurance-evaluation-data.csv",stringsAsFactors = F,header=TRUE)
#knitr::include_graphics("Definition.png")

```
## Data Exploration {.tabset}
### Addressing Missing Data: Ensuring Data Integrity for Reliable Analysis

The first step in our analysis will be to address any missing data within the dataset. This is a crucial step because missing values can distort summary statistics, hinder visualizations, and affect the performance of models if not handled properly. By identifying which columns have missing values and assessing their extent, we can decide how to manage them—whether by removing rows or columns, imputing missing values, or applying more advanced techniques. Cleaning the data in this way ensures that the subsequent exploratory data analysis (EDA) and modeling steps are based on complete and accurate data, leading to more reliable and interpretable results.

Explore the Dataset: We will use functions like head(), str(), and summary() to get an overview of your data structure, types, and initial statistics. This helps us identify potential issues early.
```{r}
str(insurance_training_data)
# Get size of the dataset
dim(insurance_test_data)
summary(insurance_test_data)
```

Initial analysis indicates that we have two target variables with data types of integer and numeric. We can use is.na() to check for missing values in these variables. For the predictor and independent variables, some have been identified as integers: KIDSDRIV, AGE, HOMEKIDS, YOJ, TIF, CLAIM_FREQ, and CAR_AGE. Similarly, is.na() will help us identify missing values in these columns. For the remaining predictor variables, we will analyze them one by one to gain a deeper understanding of the data.
## 'data.frame':    8161 obs. of  26 variables:
##  $ INDEX      : int  1 2 4 5 6 7 8 11 12 13 ...
##  $ TARGET_FLAG: int  0 0 0 0 0 1 0 1 1 0 ...
##  $ TARGET_AMT : num  0 0 0 0 0 ...
##  $ KIDSDRIV   : int  0 0 0 0 0 0 0 1 0 0 ...
##  $ AGE        : int  60 43 35 51 50 34 54 37 34 50 ...
##  $ HOMEKIDS   : int  0 0 1 0 0 1 0 2 0 0 ...
##  $ YOJ        : int  11 11 10 14 NA 12 NA NA 10 7 ...
##  $ INCOME     : chr  "$67,349" "$91,449" "$16,039" NA ...
##  $ PARENT1    : chr  "No" "No" "No" "No" ...
##  $ HOME_VAL   : chr  "$0" "$257,252" "$124,191" "$306,251" ...
##  $ MSTATUS    : chr  "z_No" "z_No" "Yes" "Yes" ...
##  $ SEX        : chr  "M" "M" "z_F" "M" ...
##  $ EDUCATION  : chr  "PhD" "z_High School" "z_High School" "<High School" ...
##  $ JOB        : chr  "Professional" "z_Blue Collar" "Clerical" "z_Blue Collar" ...
##  $ TRAVTIME   : int  14 22 5 32 36 46 33 44 34 48 ...
##  $ CAR_USE    : chr  "Private" "Commercial" "Private" "Private" ...
##  $ BLUEBOOK   : chr  "$14,230" "$14,940" "$4,010" "$15,440" ...
##  $ TIF        : int  11 1 4 7 1 1 1 1 1 7 ...
##  $ CAR_TYPE   : chr  "Minivan" "Minivan" "z_SUV" "Minivan" ...
##  $ RED_CAR    : chr  "yes" "yes" "no" "yes" ...
##  $ OLDCLAIM   : chr  "$4,461" "$0" "$38,690" "$0" ...
##  $ CLM_FREQ   : int  2 0 2 0 2 0 0 1 0 0 ...
##  $ REVOKED    : chr  "No" "No" "No" "No" ...
##  $ MVR_PTS    : int  3 0 3 0 3 0 0 10 0 1 ...
##  $ CAR_AGE    : int  18 1 10 6 17 7 1 7 1 17 ...
##  $ URBANICITY : chr  "Highly Urban/ Urban" "Highly Urban/ Urban" "Highly Urban/ Urban" "Highl

```{r}

# Check for missing values in target variables
missing_target1 <- sum(is.na(insurance_training_data$TARGET_FLAG))
missing_target2 <- sum(is.na(insurance_training_data$TARGET_AMT))

cat("Missing values in target_variable1:", missing_target1, "\n")
cat("Missing values in target_variable2:", missing_target2, "\n")

# List of integer predictor variables
int_predictors <- c("KIDSDRIV", "AGE", "HOMEKIDS","TRAVTIME", "YOJ","MVR_PTS", "TIF", "CLM_FREQ", "CAR_AGE")

# Check for missing values in integer predictors
missing_ints <- sapply(insurance_training_data[int_predictors], function(x) sum(is.na(x)))

# Print missing values for integer predictors
cat("Missing values in integer predictors:\n")
print(missing_ints)



```


Now lets look at the Income Variable it is supposed to be numeric but it is identified as Char here
```{r}

# Analyze a categorical variable
Income <- "INCOME"

# Print unique values
cat("Unique values in", Income, ":\n")
print(unique(insurance_training_data[[Income]]))

# Subset the data to only include the relevant columns, including income
# This is optional but can improve efficiency
# AGE, Education, JOB, CAR_USE,TIF
#subset_data <- insurance_training_data[, c("INCOME", "other_feature1", "other_feature2", ...)]

# Perform KNN imputation
#imputed_data <- kNN(subset_data)
insurance_training_data$INCOME[insurance_training_data$INCOME == ""] <- NA



missing_income_count <- sum(is.na(insurance_training_data$INCOME))
cat("Number of missing values in the income column:", missing_income_count, "\n")

```

For now I have just replaced the blank values in INCOME with NA and we will handle that Data Type and Imputation in later steps.\


Lets look at the Parent1 field which is suppose to be a simple YES/NO field
```{r}
table(insurance_training_data$PARENT1)
#HOME_VAL
```

First we will look at the TARGET_FLAG and understand the distribution of the data

```{r}
table(insurance_training_data$TARGET_FLAG)
ggplot(insurance_training_data, aes(x = factor(TARGET_FLAG))) + geom_bar()

```


```{r}

#insurance_training_data$TARGET_FLAG <- factor(insurance_training_data$TARGET_FLAG, levels = c(0, 1))

#table(insurance_training_data$TARGET_FLAG_FACTOR)

# Apply SMOTE to the dataset
#X <- insurance_training_data[, -which(names(insurance_training_data) == "TARGET_FLAG_FACTOR")]
#target <- insurance_training_data$TARGET_FLAG_FACTOR
# Apply SMOTE
#str(X)
#summary(insurance_training_data)
# Convert categorical variables to dummy variables
#insurance_training_data_numeric <- data.frame(model.matrix(~ . - 1, data = insurance_training_data))

# Apply SMOTE after conversion
#smote_data <- SMOTE(insurance_training_data_numeric[, -which(names(insurance_training_data_numeric) == "TARGET_FLAG")], 
                  #  insurance_training_data_numeric$TARGET_FLAG)



# Combine the oversampled data with the original data
#insurance_training_data$TARGET_FLAG_FACTOR <- smote_result$data

#table(insurance_training_data$TARGET_FLAG_FACTOR)

```
### Imputing Missing Values 

Now that we have some idea about some 

```{r}
# 1. Missing Value Analysis



# Check the number of missing (NA) values in INCOME
# Convert empty strings, 0, or other placeholders to NA
insurance_training_data$INCOME[insurance_training_data$INCOME == "" | insurance_training_data$INCOME == 0] <- NA

sum(is.na(insurance_training_data$INCOME))
# Visualize missing values
aggr(insurance_training_data, numbers = TRUE, prop = FALSE, col = c('navyblue', 'yellow'))

# Comment: The `aggr()` function from the VIM package provides a visual representation of missing values. 
# Here, we can easily identify which columns have missing data and the proportion of missing values.

```

### Data Explorer Report

Data Explorer Report

```{r}
# 2. Data Distribution Analysis
# Create a report of the data using DataExplorer
#create_report(insurance_test_data)

# Comment: The `create_report()` function gives a comprehensive overview of the dataset, including distributions, 
# summary statistics, and visualizations for each variable.

# 3. Summary Statistics for Continuous Variables
summary_stats <- insurance_test_data %>%
  summarise(
    Mean_AGE = mean(AGE, na.rm = TRUE),
    Median_AGE = median(AGE, na.rm = TRUE),
    SD_AGE = sd(AGE, na.rm = TRUE),
    Mean_INCOME = mean(INCOME, na.rm = TRUE),
    Median_INCOME = median(INCOME, na.rm = TRUE),
    SD_INCOME = sd(INCOME, na.rm = TRUE)
  )

print(summary_stats)
```