---
title: "GROUP 2 HW4: Insurance - Data 621 Assignment 4"
author: 'GROUP 2 MEMBERS: Banu Boopalan, Gregg Maloy, Alexander Moyse, Umais Siddiqui'
date: "10/26/2024"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 2 
  html_document:
    highlight: pygments
    number_sections: no
    theme: flatly
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE)
```

```{r libraries, include=FALSE}


# Libraries


library(stringr)
library(tidyr)
library(DataExplorer)        
library(dplyr)
library(visdat)
library(pROC)
library(mice)
library(corrplot)
library(MASS)
library(caret)
library(e1071)
library(rbin)
library(bestNormalize)
library(GGally)
library(ggplot2)
library(readr)
library(reshape2)
library(purrr)
library(leaps)
# Load necessary package
library(caTools)
library(car)  # For VIF
library(glmnet)
library(caTools)

```


```{r data}
# training data
insurance_training_data <- read.csv('https://raw.githubusercontent.com/umais/DATA/refs/heads/main/insurance_training_data.csv', stringsAsFactors =  FALSE)
# test data
insurance_evaluation_data <- read.csv('https://raw.githubusercontent.com/umais/DATA/refs/heads/main/insurance-evaluation-data.csv')
```




# Data Exploration

## Overview


In this assignment, you’ll dive into a rich dataset of approximately 8,000 customer records from an auto insurance company. Each record represents a customer and includes two key response variables:

TARGET_FLAG - A binary indicator where a “1” signifies the customer was involved in a car crash, while a “0” means they were not.
TARGET_AMT - This variable represents the cost incurred in the event of a crash. If there was no crash, this value is zero. If a crash occurred, this variable holds the associated monetary cost, which is greater than zero.
Your goal is to develop predictive models that provide insights on two fronts:

The likelihood of a customer being involved in a car crash (using binary logistic regression).
The potential cost of a crash, if it occurs (using multiple linear regression).
For this task, you’ll leverage the variables in the dataset—and any additional variables you derive from them—to create, train, and evaluate your models on a training dataset.



## Crash Data Insights

### Dataset Variables Overview:
This table outlines key attributes in our insurance dataset, detailing both the target variables and the predictor variables, along with their expected impacts on insurance outcomes. We aldo find a brief description of each variable in the dataset to help guide your exploratory analysis and feature engineering efforts.

### Target Variables

| **Attribute**     | **Description**                              | **Expected Impact**                                 |
|-------------------|----------------------------------------------|----------------------------------------------------|
| TARGET_FLAG       | Indicates if the customer was involved in a crash (1 = Yes, 0 = No) | None at this stage                                 |
| TARGET_AMT        | Cost incurred in the event of a crash (0 if no crash) | None at this stage                                 |

---

### Predictor Variables

| **Attribute**     | **Description**                              | **Theoretical Influence**                          |
|-------------------|----------------------------------------------|----------------------------------------------------|
| AGE               | Driver's age                                 | Young and very old drivers may have higher risks   |
| BLUEBOOK          | Vehicle market value                         | May affect payout size if a crash occurs           |
| CAR_AGE           | Vehicle's age                                | Possibly influences payout but unclear on crash likelihood |
| CAR_TYPE          | Vehicle type                                 | Potential influence on payout if a crash occurs    |
| CAR_USE           | Vehicle's primary use                        | Commercial usage may increase crash probability    |
| CLM_FREQ          | Claims made in past 5 years                 | More past claims may predict higher future claims  |
| EDUCATION         | Highest education level attained            | Higher education might correlate with safer driving|
| HOMEKIDS          | Number of children at home                  | Impact unknown                                     |
| HOME_VAL          | Value of home                               | Homeownership could correlate with responsible driving |
| INCOME            | Annual income                               | Wealthier individuals may experience fewer crashes |
| JOB               | Employment category                         | White-collar jobs might suggest safer driving      |
| KIDSDRIV          | Number of young drivers in household        | Teen drivers could increase crash risk             |
| MSTATUS           | Marital status                              | Married individuals may drive more cautiously      |
| MVR_PTS           | Points on motor vehicle record              | Higher points suggest increased crash likelihood   |
| OLDCLAIM          | Cumulative claims in past 5 years           | High past payouts may predict future claims        |
| PARENT1           | Single-parent household indicator           | Impact unknown                                     |
| RED_CAR           | Indicator for a red car                     | Potential correlation with risky driving (myth)    |
| REVOKED           | Past license revocation (in last 7 years)   | Suggests increased risk                            |
| SEX               | Driver's gender                             | Myth suggests women may experience fewer crashes   |
| TIF               | Policy duration (years)                     | Long-term policyholders may have safer driving patterns |
| TRAVTIME          | Commute duration                            | Longer commutes may indicate higher risk           |
| URBANICITY        | Urban or rural setting                      | Impact unknown                                     |
| YOJ               | Years in current job                        | Stable employment may suggest safer driving habits |




The dataset includes 8,161 records with 23 feature variables and 2 target variables, providing detailed information on customers and their insurance claims history.

On preliminary inspection, we note that several columns contain issues such as incompatible punctuation in financial values, and categorical variables require conversion to factors with clearer labels. 

```{r, overview}
# Check the structure of the data
glimpse(insurance_training_data)

```

```{r,head}
# Display the first few rows and a summary
head(insurance_training_data)
summary(insurance_training_data)
```





```{r, numeric-vars}
# Remove an index column if present
insurance_training_data_clean <- dplyr::select(insurance_training_data, -INDEX)

# Clean special characters in financial columns
insurance_training_data_clean$HOME_VAL <- substr(insurance_training_data_clean$HOME_VAL, 2, nchar(insurance_training_data_clean$HOME_VAL)) 
insurance_training_data_clean$HOME_VAL <- as.numeric(str_remove_all(insurance_training_data_clean$HOME_VAL, "[[:punct:]]"))

insurance_training_data_clean$BLUEBOOK <- substr(insurance_training_data_clean$BLUEBOOK, 2, nchar(insurance_training_data_clean$BLUEBOOK))
insurance_training_data_clean$BLUEBOOK <- as.numeric(str_remove_all(insurance_training_data_clean$BLUEBOOK, "[[:punct:]]"))

insurance_training_data_clean$INCOME <- substr(insurance_training_data_clean$INCOME, 2, nchar(insurance_training_data_clean$INCOME))
insurance_training_data_clean$INCOME <- as.numeric(str_remove_all(insurance_training_data_clean$INCOME, "[[:punct:]]"))

insurance_training_data_clean$OLDCLAIM <- substr(insurance_training_data_clean$OLDCLAIM, 2, nchar(insurance_training_data_clean$OLDCLAIM))
insurance_training_data_clean$OLDCLAIM <- as.numeric(str_remove_all(insurance_training_data_clean$OLDCLAIM, "[[:punct:]]"))

```


```{r, categorical-vars}

# Remove 'z_' prefix from marital status and convert to a factor
insurance_training_data_clean$MSTATUS <- as.factor(str_remove(insurance_training_data_clean$MSTATUS, 'z_'))

# Remove 'z_' prefix from parental status and convert to a factor
insurance_training_data_clean$PARENT1 <- as.factor(str_remove(insurance_training_data_clean$PARENT1, 'z_'))

# Replace '<' with 'Less than ' in education level to clarify the meaning
insurance_training_data_clean$EDUCATION <- str_replace(insurance_training_data_clean$EDUCATION, '<', 'Less than ')

# Remove 'z_' prefix from sex and convert to a factor
insurance_training_data_clean$SEX <- as.factor(str_remove(insurance_training_data_clean$SEX, 'z_'))

# Remove 'z_' prefix from education level and convert to a factor
insurance_training_data_clean$EDUCATION <- as.factor(str_remove(insurance_training_data_clean$EDUCATION, 'z_'))

# Recode empty job entries as 'Other Job' to handle missing data
insurance_training_data_clean$JOB[insurance_training_data_clean$JOB == ""] <- 'Other Job'

# Remove 'z_' prefix from job titles and convert to a factor
insurance_training_data_clean$JOB <- as.factor(str_remove(insurance_training_data_clean$JOB, 'z_'))

# Remove 'z_' prefix from car usage category and convert to a factor
insurance_training_data_clean$CAR_USE <- as.factor(str_remove(insurance_training_data_clean$CAR_USE, 'z_'))

# Remove 'z_' prefix from car type and convert to a factor
insurance_training_data_clean$CAR_TYPE <- as.factor(str_remove(insurance_training_data_clean$CAR_TYPE, 'z_'))

# Remove 'z_' prefix from urbanicity status and convert to a factor
insurance_training_data_clean$URBANICITY <- as.factor(str_remove(insurance_training_data_clean$URBANICITY, 'z_'))

# Remove 'z_' prefix from revoked status and convert to a factor
insurance_training_data_clean$REVOKED <- as.factor(str_remove(insurance_training_data_clean$REVOKED, 'z_'))

# Remove 'z_' prefix from red car indicator and convert to a factor
insurance_training_data_clean$RED_CAR <- as.factor(str_remove(insurance_training_data_clean$RED_CAR, 'z_'))

```


```{r, after-fix}

summary(insurance_training_data_clean)

```


The updated data frame now comprises only numeric and factor columns. It is observed that the car age variable contains values less than 1, including negative values. These will be replaced with a mode value of 1 to ensure data integrity.


```{r, car-age}
insurance_training_data_clean$CAR_AGE[insurance_training_data_clean$CAR_AGE <1] <- 1
```


```{r}

insurance_evaluation_data_clean <- dplyr::select(insurance_evaluation_data, -INDEX)
insurance_evaluation_data_clean$HOME_VAL <- substr(insurance_evaluation_data_clean$HOME_VAL, 2, nchar(insurance_evaluation_data_clean$HOME_VAL)) 
insurance_evaluation_data_clean$HOME_VAL <- as.numeric(str_remove_all(insurance_evaluation_data_clean$HOME_VAL, "[[:punct:]]"))

insurance_evaluation_data_clean$BLUEBOOK <- substr(insurance_evaluation_data_clean$BLUEBOOK, 2, nchar(insurance_evaluation_data_clean$BLUEBOOK))
insurance_evaluation_data_clean$BLUEBOOK <- as.numeric(str_remove_all(insurance_evaluation_data_clean$BLUEBOOK, "[[:punct:]]"))

insurance_evaluation_data_clean$INCOME <- substr(insurance_evaluation_data_clean$INCOME, 2, nchar(insurance_evaluation_data_clean$INCOME))
insurance_evaluation_data_clean$INCOME <- as.numeric(str_remove_all(insurance_evaluation_data_clean$INCOME, "[[:punct:]]"))

insurance_evaluation_data_clean$OLDCLAIM <- substr(insurance_evaluation_data_clean$OLDCLAIM, 2, nchar(insurance_evaluation_data_clean$OLDCLAIM))
insurance_evaluation_data_clean$OLDCLAIM <- as.numeric(str_remove_all(insurance_evaluation_data_clean$OLDCLAIM, "[[:punct:]]"))

# Remove 'z_' prefix from marital status and convert to a factor
insurance_evaluation_data_clean$MSTATUS <- as.factor(str_remove(insurance_evaluation_data_clean$MSTATUS, 'z_'))

# Remove 'z_' prefix from parental status and convert to a factor
insurance_evaluation_data_clean$PARENT1 <- as.factor(str_remove(insurance_evaluation_data_clean$PARENT1, 'z_'))

# Replace '<' with 'Less than ' in education level to clarify the meaning
insurance_evaluation_data_clean$EDUCATION <- str_replace(insurance_evaluation_data_clean$EDUCATION, '<', 'Less than ')

# Remove 'z_' prefix from sex and convert to a factor
insurance_evaluation_data_clean$SEX <- as.factor(str_remove(insurance_evaluation_data_clean$SEX, 'z_'))

# Remove 'z_' prefix from education level and convert to a factor
insurance_evaluation_data_clean$EDUCATION <- as.factor(str_remove(insurance_evaluation_data_clean$EDUCATION, 'z_'))

# Recode empty job entries as 'Other Job' to handle missing data
insurance_evaluation_data_clean$JOB[insurance_evaluation_data_clean$JOB == ""] <- 'Other Job'

# Remove 'z_' prefix from job titles and convert to a factor
insurance_evaluation_data_clean$JOB <- as.factor(str_remove(insurance_evaluation_data_clean$JOB, 'z_'))

# Remove 'z_' prefix from car usage category and convert to a factor
insurance_evaluation_data_clean$CAR_USE <- as.factor(str_remove(insurance_evaluation_data_clean$CAR_USE, 'z_'))

# Remove 'z_' prefix from car type and convert to a factor
insurance_evaluation_data_clean$CAR_TYPE <- as.factor(str_remove(insurance_evaluation_data_clean$CAR_TYPE, 'z_'))

# Remove 'z_' prefix from urbanicity status and convert to a factor
insurance_evaluation_data_clean$URBANICITY <- as.factor(str_remove(insurance_evaluation_data_clean$URBANICITY, 'z_'))

# Remove 'z_' prefix from revoked status and convert to a factor
insurance_evaluation_data_clean$REVOKED <- as.factor(str_remove(insurance_evaluation_data_clean$REVOKED, 'z_'))

# Remove 'z_' prefix from red car indicator and convert to a factor
insurance_evaluation_data_clean$RED_CAR <- as.factor(str_remove(insurance_evaluation_data_clean$RED_CAR, 'z_'))



insurance_evaluation_data_clean$CAR_AGE[insurance_evaluation_data_clean$CAR_AGE <1] <- 1



```

## Categorical variables

```{r, levels}
# Identify categorical columns and store their names in cat_features
cat_features <- names(insurance_training_data_clean)[map_chr(insurance_training_data_clean, class) == "factor"]

# Display each categorical column and its unique levels
cat("Exploring Categorical Features:\n")
walk(cat_features, ~cat("Feature:", ., "\nLevels:", paste(levels(insurance_training_data_clean[[.]]), collapse = ", "), "\n\n"))


```

Upon examining the categorical variables, it is observed that the majority of the columns are binary in nature.

The following graphs illustrate the distribution of all categorical predictors.

```{r, cat-bar, fig.length =20, fig.width=10}

# Select categorical features from the cleaned insurance training data
categorical_data <- insurance_training_data_clean[cat_features]

# Melt the data frame to create a long format suitable for ggplot
melted_data <- melt(categorical_data, measure.vars = cat_features, variable.name = 'category', value.name = 'category_value')

# Create a bar plot to visualize the distribution of categorical predictors
ggplot(melted_data, aes(x = category_value)) + 
  geom_bar(aes(fill = category_value)) + 
  scale_fill_brewer(palette = "Set1") + 
  facet_wrap(~ category, nrow = 5L, scales = 'free') + 
  coord_flip() +
  labs(title = "Distribution of Categorical Predictors", 
       x = "Category Value", 
       y = "Count") +
  theme_minimal()
```



## Numeric Variables

The following two graphs illustrate the distribution of the numeric variables in our dataset. The first set of histograms, represented in red, displays the distributions on a normal scale, while the second set, depicted in blue, presents the distributions on a log10 scale. Notably, many numeric variables exhibit a mode value of zero, which may warrant further investigation.

```{r, histograms}
plot_histogram(insurance_training_data_clean, geom_histogram_args = list("fill" = "tomato4"))


```




```{r, log10-hist}
plot_histogram(insurance_training_data_clean, scale_x = "log10", geom_histogram_args = list("fill" = "royalblue4"))

```

## Assessment of Incomplete Data


This section identifies columns within the dataset that contain missing values, denoted as NA:


```{r,missing-val}
# Summarize the dataset to check for columns with missing values
insurance_training_data_clean %>% 
  summarise_all(funs(sum(is.na(.)))) %>% 
  select_if(~any(.) > 0)

```


```{r, plot-miss, fig.width=10, fig.length=10}
# Visualize the missing values in the dataset to understand their distribution
plot_missing(insurance_training_data_clean)

```




```{r, missing-values}

# Calculate and display the proportion of missing values for each column
round(colSums(is.na(insurance_training_data_clean)) / nrow(insurance_training_data_clean), 3)

# Visualize specific columns to further investigate missing data patterns
vis_dat(insurance_training_data_clean %>% dplyr::select(YOJ, INCOME, HOME_VAL, CAR_AGE))



```

The analysis reveals that five variables contain missing values. However, there does not appear to be a discernible pattern associated with these missing entries, which suggests they are likely missing at random (MAR). This conclusion allows us to proceed with standard imputation techniques or analyses without significant concern regarding bias introduced by the missing data.

## Handling Missing Values And Correlation Analysis

Multiple Imputation by Chained Equations (MICE) is a powerful method for handling missing data, as it generates multiple complete datasets by predicting missing values based on other available data. This method accounts for uncertainty in the imputations and allows for more reliable statistical inference.

```{r, corrplot}

# Select numeric columns for correlation analysis
numeric_data <- insurance_training_data_clean[, c('TARGET_AMT', 'AGE', 'YOJ', 'INCOME', 'HOME_VAL', 'TRAVTIME', 'BLUEBOOK', 'TIF', 'OLDCLAIM', 'CLM_FREQ', 'MVR_PTS', 'CAR_AGE')]

numeric_data_eval <- insurance_evaluation_data_clean[, c('TARGET_AMT', 'AGE', 'YOJ', 'INCOME', 'HOME_VAL', 'TRAVTIME', 'BLUEBOOK', 'TIF', 'OLDCLAIM', 'CLM_FREQ', 'MVR_PTS', 'CAR_AGE')]

# Document missing values before imputation
missing_summary_before <- colSums(is.na(numeric_data))
print("Missing Values Before Imputation:")
print(missing_summary_before)

# Perform multiple imputation
imputed_data <- mice(numeric_data, m = 5, method = 'pmm', seed = 123) # Predictive Mean Matching

# Create a complete dataset by averaging the multiple imputations
completed_data <- complete(imputed_data)

imputed_data_eval<- mice(numeric_data_eval, m = 5, method = 'pmm', seed = 123) # Predictive Mean Matching
completed_data_eval <- complete(imputed_data_eval)
# Document missing values after imputation
missing_summary_after <- colSums(is.na(completed_data))
print("Missing Values After Imputation:")
print(missing_summary_after)

# Generate a correlation matrix and plot it
corrplot(cor(completed_data), type = "upper")


# Sensitivity Analysis
# Compare correlations from original data (complete case analysis) vs. imputed data

# Complete case analysis (removing rows with NA values)
complete_case_data <- na.omit(numeric_data)
cor_complete_case <- cor(complete_case_data)

# Correlation of imputed data
cor_imputed <- cor(completed_data)

# Print correlation matrices for comparison
print("Correlation Matrix for Complete Case Analysis:")
print(cor_complete_case)

print("Correlation Matrix for Imputed Data:")
print(cor_imputed)

# Visualize the difference in correlations
cor_diff <- cor_imputed - cor_complete_case
ggplot(melt(cor_diff), aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", limit = c(-1, 1), name="Correlation Difference") +
  theme_minimal() +
  labs(title = "Difference in Correlation between Imputed and Complete Case Data", x = "Variables", y = "Variables") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

After completing the data, we have calculated the correlation matrix on the fully imputed dataset. This provides a more accurate representation of the relationships between variables without the bias that could be introduced by simple imputation methods.

It is evident that there are notable positive correlations among the following variables:

Income and Home Value
Income and Bluebook Value
Income and Car Age
Claim Frequency and Old Claims
Claim Frequency and MVR Points

The heatmap provides a visual representation of the differences in correlations between the imputed data and complete case data, helping to understand the impact of the missing data handling method.

# Data Preparation for Multiple Linear Regression


## Removing TARGET_FLAG
Since, for multiple linear regression our objective is to predict the monetary amount of how much it will cost in the event of a crash, we will exclude the TARGET_FLAG variable from our analysis.

```{r remove-target-flag}
crash_data <- subset(filter(insurance_training_data_clean,TARGET_FLAG==1),select = -c(TARGET_FLAG))

```

## Handling Missing Data - Multiple Linear Regression

Before proceeding with imputation, let's assess the missing values in our dataset. We will then handle the missing data using multiple imputation, which is a more robust method than simply replacing missing values with the median.

```{r fix-nulls}
# Check for missing values before imputation
missing_summary_before <- colSums(is.na(crash_data))
print("Missing Values Before Imputation:")
print(missing_summary_before)



# Impute missing values
imputed_data <- mice(crash_data, m = 5, method = 'pmm', seed = 123) # Predictive Mean Matching
crash_data_imputed <- complete(imputed_data)



# Check for missing values after imputation
missing_summary_after <- colSums(is.na(crash_data_imputed))
print("Missing Values After Imputation:")
print(missing_summary_after)

crash_data_imputed <- na.omit(crash_data_imputed)

```


## Transformatiions - Multiple Linear Regression

We will be performing transformations and create histograms for several variables, which helps visualize the effect of the transformations on data distribution. Here's a breakdown of how these transformations aid in model building and potential outcomes:

### Handling Skewness:

Many of these variables (e.g., INCOME, HOME_VAL, OLDCLAIM) may be right-skewed due to outliers or a large range of values. Transformations like log, square root, and Yeo-Johnson help normalize the distribution, reducing skewness.
Normalized distributions (closer to normal) are beneficial for regression-based models, as they assume linear relationships and normally distributed residuals.

### Improving Model Fit:

Log and Square Root transformations compress the range of values, which can make the data easier for linear models to handle. For instance, high-income values may dominate the predictive power of INCOME if not transformed.
Box-Cox and Yeo-Johnson transformations (which automatically choose an optimal transformation) can help produce more linearly related predictors, which improves linear regression model accuracy.

### Comparing the Effect of Transformations:

Creating side-by-side histograms allows you to compare the original and transformed distributions. This visual analysis is important for selecting the transformation that brings the distribution closest to normality, which can ultimately improve the performance and interpretability of the model.

### Categorizing Continuous Variables:

The cut function is used to create binned categories for TIF (Years with Policy) and MVR_PTS (Driving Record Points), which converts continuous variables into categorical bins. This is useful if there are distinct groups within the data that are meaningful (e.g., "Less than 1 year" in TIF).
Using Transformed Variables for Modeling
After determining the most effective transformation for each variable, we can replace the original variables with the transformed ones in our model. However, it’s also useful to keep both versions to allow for comparison in model performance. Here’s how to proceed with this:

r
```{r}
# Create a histogram and density plot for the AGE variable
ggplot(crash_data_imputed, aes(x = AGE)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_density(aes(y = ..count.. * 1), fill = "lightgreen", alpha = 0.5) +
  labs(title = "Distribution of AGE", x = "AGE", y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Create a histogram for the INCOME variable
ggplot(data = crash_data_imputed, aes(x = INCOME)) +
    geom_histogram(bins = 30, fill = "lightblue", color = "black") +
    labs(title = "Distribution of INCOME",
         x = "Income",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title


# Create a histogram for the HOME_VAL variable
ggplot(data = crash_data_imputed, aes(x = HOME_VAL)) +
    geom_histogram(bins = 30, fill = "lightcoral", color = "black") +
    labs(title = "Distribution of HOME_VAL",
         x = "Home Value",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Create a histogram for the CAR_AGE variable
ggplot(data = crash_data_imputed, aes(x = CAR_AGE)) +
    geom_histogram(bins = 30, fill = "lightblue", color = "black") +
    labs(title = "Distribution of CAR_AGE",
         x = "Car Age",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Create a histogram for the BLUEBOOK variable
ggplot(data = crash_data_imputed, aes(x = BLUEBOOK)) +
    geom_histogram(bins = 30, fill = "lightgreen", color = "black") +
    labs(title = "Distribution of BLUEBOOK",
         x = "Blue Book Value",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Create a histogram for the OLDCLAIM variable
ggplot(data = crash_data_imputed, aes(x = OLDCLAIM)) +
    geom_histogram(bins = 30, fill = "lightcoral", color = "black") +
    labs(title = "Distribution of OLDCLAIM",
         x = "Old Claim Amount",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Create a histogram for the TRAVTIME variable
ggplot(data = crash_data_imputed, aes(x = TRAVTIME)) +
    geom_histogram(bins = 30, fill = "lightsalmon", color = "black") +
    labs(title = "Distribution of TRAVTIME",
         x = "Travel Time",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title
# Histogram for TIF (Number of Years with Policy)
ggplot(data = crash_data_imputed, aes(x = TIF)) +
    geom_histogram(bins = 30, fill = "lightblue", color = "black") +
    labs(title = "Distribution of TIF (Number of Years with Policy)",
         x = "Years with Policy (TIF)",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Histogram for MVR_PTS (Driving Record Points)
ggplot(data = crash_data_imputed, aes(x = MVR_PTS)) +
    geom_histogram(bins = 30, fill = "lightgreen", color = "black") +
    labs(title = "Distribution of MVR_PTS (Driving Record Points)",
         x = "Driving Record Points (MVR_PTS)",
         y = "Frequency") +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Example variable to transform
home_val_variable <- crash_data_imputed$HOME_VAL  # Replace with your actual variable

# 1. Log Transformation
home_val_log_transformed <- log(home_val_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
home_val_sqrt_transformed <- sqrt(home_val_variable+ 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
home_val_box_cox_transformed <- boxcox(home_val_variable + 1)  # Add 1 to handle zeros, need to extract lambda

home_val_yj_transformed <- bestNormalize(home_val_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (home_val_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(home_val_variable, main="Original", xlab="HOME_VAL")
hist(home_val_log_transformed, main="Log Transformed", xlab="Log(HOME_VAL)")
hist(home_val_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(HOME_VAL)")
hist(home_val_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(HOME_VAL)")


# Example variable to transform
age_variable <- crash_data_imputed$AGE  # Replace with your actual variable

# 1. Log Transformation
age_log_transformed <- log(age_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
age_sqrt_transformed <- sqrt(age_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
age_box_cox_transformed <- boxcox(age_variable + 1)  # Add 1 to handle zeros, need to extract lambda

age_yj_transformed <- bestNormalize(age_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (age_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(age_variable, main="Original", xlab="AGE")
hist(age_log_transformed, main="Log Transformed", xlab="Log(AGE)")
hist(age_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(AGE)")
hist(age_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(AGE)")


# Example variable to transform
income_variable <- crash_data_imputed$INCOME  # Replace with your actual variable

# 1. Log Transformation
income_log_transformed <- log(income_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
income_sqrt_transformed <- sqrt(income_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
income_box_cox_transformed <- boxcox(income_variable + 1)  # Add 1 to handle zeros, need to extract lambda

income_yj_transformed <- bestNormalize(income_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (income_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(income_variable, main="Original", xlab="INCOME")
hist(income_log_transformed, main="Log Transformed", xlab="Log(INCOME)")
hist(income_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(INCOME)")
hist(income_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(INCOME)")


#OldClaim


oldclaim_variable <- crash_data_imputed$OLDCLAIM  # Replace with your actual variable

oldclaim_log_transformed <- log(oldclaim_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
oldclaim_sqrt_transformed <- sqrt(oldclaim_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
oldclaim_box_cox_transformed <- boxcox(oldclaim_variable + 1)  # Add 1 to handle zeros, need to extract lambda

oldclaim_yj_transformed <- bestNormalize(oldclaim_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (oldclaim_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(oldclaim_variable, main="Original", xlab="oldclaim")
hist(oldclaim_log_transformed, main="Log Transformed", xlab="Log(oldclaim)")
hist(oldclaim_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(oldclaim)")
hist(oldclaim_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(oldclaim)")

# CAR AGE
car_age_variable <- crash_data_imputed$CAR_AGE # Replace with your actual variable

car_age_log_transformed <- log(car_age_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
car_age_sqrt_transformed <- sqrt(car_age_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
car_age_box_cox_transformed <- boxcox(car_age_variable + 1)  # Add 1 to handle zeros, need to extract lambda

car_age_yj_transformed <- bestNormalize(car_age_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (car_age_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(car_age_variable, main="Original", xlab="CAR_AGE")
hist(car_age_log_transformed, main="Log Transformed", xlab="Log(CAR_AGE)")
hist(car_age_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(CAR_AGE)")
hist(car_age_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(CAR_AGE)")


#TRAVTIME TRANSFORMATIONS

TRAVTIME_variable <- crash_data_imputed$TRAVTIME # Replace with your actual variable

TRAVTIME_log_transformed <- log(TRAVTIME_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
TRAVTIME_sqrt_transformed <- sqrt(TRAVTIME_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
TRAVTIME_box_cox_transformed <- boxcox(TRAVTIME_variable + 1)  # Add 1 to handle zeros, need to extract lambda

TRAVTIME_yj_transformed <- bestNormalize(TRAVTIME_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (TRAVTIME_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(TRAVTIME_variable, main="Original", xlab="TRAVTIME")
hist(TRAVTIME_log_transformed, main="Log Transformed", xlab="Log(TRAVTIME)")
hist(TRAVTIME_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(TRAVTIME)")
hist(TRAVTIME_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(TRAVTIME)")

#TIF

TIF_variable <- crash_data_imputed$TIF # Replace with your actual variable

TIF_log_transformed <- log(TIF_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
TIF_sqrt_transformed <- sqrt(TIF_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
TIF_box_cox_transformed <- boxcox(TIF_variable + 1)  # Add 1 to handle zeros, need to extract lambda

TIF_yj_transformed <- bestNormalize(TIF_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (TIF_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(TIF_variable, main="Original", xlab="TIF")
hist(TIF_log_transformed, main="Log Transformed", xlab="Log(TIF)")
hist(TIF_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(TIF)")
hist(TIF_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(TIF)")

#MVR_PTS TRANSFORMATIONS

MVR_PTS_variable <- crash_data_imputed$MVR_PTS # Replace with your actual variable

MVR_PTS_log_transformed <- log(MVR_PTS_variable + 1)  # Add 1 to handle zeros

# 2. Square Root Transformation
MVR_PTS_sqrt_transformed <- sqrt(MVR_PTS_variable + 1)  # Add 1 to handle zeros

# 3. Box-Cox Transformation
MVR_PTS_box_cox_transformed <- boxcox(MVR_PTS_variable + 1)  # Add 1 to handle zeros, need to extract lambda

MVR_PTS_yj_transformed <- bestNormalize(MVR_PTS_variable, method = "yeo.johnson")$x.t

# 5. Inverse Transformation
inverse_transformed <- 1 / (MVR_PTS_variable + 1)  # Add 1 to handle zeros

# Check the results with histograms
par(mfrow=c(2,2))  # Set up the plotting area
hist(MVR_PTS_variable, main="Original", xlab="MVR_PTS")
hist(MVR_PTS_log_transformed, main="Log Transformed", xlab="Log(MVR_PTS)")
hist(MVR_PTS_sqrt_transformed, main="Square Root Transformed", xlab="Sqrt(MVR_PTS)")
hist(MVR_PTS_yj_transformed, main="Yeo-Johnson Transformed", xlab="Yeo-Johnson(MVR_PTS)")

crash_data_imputed_transformed <- crash_data_imputed %>%
    mutate(
                # Log transformation of AGE
        INCOME_transformed = bestNormalize(INCOME, method = "yeo.johnson")$x.t,      # Log transformation of INCOME
        CAR_AGE_transformed = sqrt(CAR_AGE + 1),  # Square root transformation of CAR_AGE
        HOME_VAL_transformed = sqrt(HOME_VAL + 1),   # Log transformation of HOME_VAL
        OLDCLAIM_transformed=bestNormalize(oldclaim_variable, method = "yeo.johnson")$x.t,
        TRAVTIME_transformed=sqrt(TRAVTIME + 1)

        )
```


# Build Models

## Multiple Linear Regression
### Model 1

I am choosing OLDCLAIM, CLM_FREQ, MVR_PTS, and TRAVTIME based on their potential relevance to accurately estimating TARGET_AMT, reflecting key factors associated with claims risk, customer behavior, and exposure. Here’s why each predictor is chosen:

OLDCLAIM: This variable likely captures historical claim amounts, which can be indicative of a customer’s risk profile and claim tendencies. Including past claims can help predict future claims or costs, especially if there’s a pattern of high claims.

CLM_FREQ: Claim frequency directly indicates how often a customer has filed claims. High claim frequency often correlates with increased future claims risk, making it an essential variable for understanding claim cost patterns.

MVR_PTS: Motor Vehicle Record (MVR) points typically reflect a driver’s record of traffic violations or accidents. Higher MVR points generally correspond to higher risk profiles, making this variable crucial for predicting future claims and associated costs.

TRAVTIME: The time a customer spends traveling, TRAVTIME, can be a proxy for exposure to risk (e.g., more time on the road increases accident likelihood). Including this variable helps account for the time-related risk factor in claims prediction.

### Fitting a linear regression model with transformed variables
```{r}


# Set seed for reproducibility
set.seed(123)  # You can set any number

# Create a split index
split <- sample.split(crash_data_imputed_transformed$TARGET_AMT, SplitRatio = 0.7)

# Split data into training and testing sets
train_data <- subset(crash_data_imputed_transformed, split == TRUE)
test_data <- subset(crash_data_imputed_transformed, split == FALSE)

# Fit the model on the training data
model <- lm(TARGET_AMT ~ train_data$OLDCLAIM_transformed + train_data$CLM_FREQ + train_data$MVR_PTS + train_data$TRAVTIME_transformed, data = train_data)
summary(model)

# Predict on the testing data
predictions <- predict(model, newdata = test_data)

# Evaluate model performance
# Calculate Mean Absolute Error (MAE)
MAE <- mean(abs(predictions - test_data$TARGET_AMT))

# Calculate Mean Squared Error (MSE)
MSE <- mean((predictions - test_data$TARGET_AMT)^2)

# Calculate Root Mean Squared Error (RMSE)
RMSE <- sqrt(MSE)

# Print the performance metrics
cat("Model Performance on Testing Data:\n")
cat("Mean Absolute Error (MAE):", MAE, "\n")
cat("Mean Squared Error (MSE):", MSE, "\n")
cat("Root Mean Squared Error (RMSE):", RMSE, "\n")

```

As we can see this model does not provide a meaningful fit for the data and shows large prediction errors. Consider alternative predictors or transformations, adding interaction terms, or using a different modeling approach, as the current variables are likely insufficient for capturing the patterns in the outcome.


### Model 2

I will take a straightforward approach by utilizing the variables as they are, applying only basic data cleaning and ensuring the data is complete.  

```{r}



# Set seed for reproducibility
set.seed(123)  # You can set any number

# Create a split index
split <- sample.split(completed_data$TARGET_AMT, SplitRatio = 0.7)

# Split data into training and testing sets
train_data <- subset(completed_data , split == TRUE)
test_data <- subset(completed_data , split == FALSE)

# Fit the model on the training data
model <- lm(TARGET_AMT ~ train_data$OLDCLAIM + train_data$CLM_FREQ + train_data$MVR_PTS + train_data$TRAVTIME, data = train_data)
summary(model)

# Predict on the testing data
predictions <- predict(model, newdata = test_data)

# Evaluate model performance
# Calculate Mean Absolute Error (MAE)
MAE <- mean(abs(predictions - test_data$TARGET_AMT))

# Calculate Mean Squared Error (MSE)
MSE <- mean((predictions - test_data$TARGET_AMT)^2)

# Calculate Root Mean Squared Error (RMSE)
RMSE <- sqrt(MSE)

# Print the performance metrics
cat("Model Performance on Testing Data:\n")
cat("Mean Absolute Error (MAE):", MAE, "\n")
cat("Mean Squared Error (MSE):", MSE, "\n")
cat("Root Mean Squared Error (RMSE):", RMSE, "\n")

```

The second model performs substantially better than the first across all metrics. The inclusion of statistically significant predictors (CLM_FREQ, MVR_PTS, TRAVTIME) improves both the fit and prediction accuracy, making it a more suitable model for forecasting purposes. However, the relatively low R-squared value suggests that additional variables or model refinement could further enhance performance.


### Model 3

```{r}

# Transform skewed predictors and target
train_data$TARGET_AMT_log <- log(train_data$TARGET_AMT + 1)  # Log transformation to stabilize variance
train_data$TRAVTIME_sqrt <- sqrt(train_data$TRAVTIME)  # Square root transformation for TRAVTIME


enhanced_model <- lm(
  TARGET_AMT_log ~ train_data$CLM_FREQ + train_data$MVR_PTS + train_data$TRAVTIME_sqrt +
    I(train_data$MVR_PTS^2) + train_data$CLM_FREQ:train_data$MVR_PTS,  # Interaction and polynomial terms
  data = train_data
)

# Model Summary
summary(enhanced_model)

# Model Performance on Testing Data
predictions <- predict(enhanced_model, newdata = test_data)
# Convert predictions back if log-transformed
predictions <- exp(predictions) - 1  

# Calculate Performance Metrics
mae <- mean(abs(predictions - test_data$TARGET_AMT))
mse <- mean((predictions - test_data$TARGET_AMT)^2)
rmse <- sqrt(mse)

list(MAE = mae, MSE = mse, RMSE = rmse)
```

### Significance of Predictors:

All predictors are statistically significant (p < 0.01), with high t-values and low p-values, confirming that each variable contributes meaningfully to the model.
Interaction Term (CLM_FREQ:MVR_PTS) and Polynomial Term (MVR_PTS^2) have significant coefficients, capturing more complex relationships between variables, which the previous model lacked.
Model Fit (R-Squared and Adjusted R-Squared):

Previous Model: R-squared = 0.02557, adjusted R-squared = 0.02494.
Updated Model: R-squared = 0.08821, adjusted R-squared = 0.08747.
Interpretation: This model explains about 8.8% of the variance, compared to only 2.5% in the previous model. While R-squared is still low, this is a clear improvement.
Residual Standard Error (RSE):

Previous Model: RSE = 5243.
Updated Model: RSE = 3.713 (on log scale).
Interpretation: The reduced residual error indicates this model fits closer to actual values, aligning with improved R-squared and adjusted R-squared.
Performance Metrics on Testing Data:

Previous Model: MAE = 1916.528, MSE = 4,578,380, RMSE = 2139.715.
Updated Model: MAE = 428.3723, MSE = 2,311,025, RMSE = 1520.206.
Interpretation: Lower MAE, MSE, and RMSE values show the updated model is substantially more accurate in predictions, achieving almost a 30% reduction in RMSE.


### Model 4

```{r}
# Set seed for reproducibility



enhanced_model <- lm(
    TARGET_AMT_log ~ train_data$CLM_FREQ + train_data$MVR_PTS + train_data$TRAVTIME_sqrt +  
       I(train_data$MVR_PTS^2) + train_data$CLM_FREQ:train_data$MVR_PTS + train_data$CLM_FREQ:train_data$TRAVTIME_sqrt + train_data$MVR_PTS:train_data$TRAVTIME_sqrt,
  data = train_data,
  weights = ifelse(train_data$CLM_FREQ > 2, 1.5, 1) 
)

   
# Model Summary
summary(enhanced_model)

# Model Performance on Testing Data
predictions <- predict(enhanced_model, newdata = test_data)
# Convert predictions back if log-transformed
predictions <- exp(predictions) - 1  

# Calculate Performance Metrics
mae <- mean(abs(predictions - test_data$TARGET_AMT))
mse <- mean((predictions - test_data$TARGET_AMT)^2)
rmse <- sqrt(mse)

list(MAE = mae, MSE = mse, RMSE = rmse)
```

### Model 5

```{r}
# Set seed for reproducibility



enhanced_model <- lm(
    TARGET_AMT_log ~ train_data$CLM_FREQ + train_data$MVR_PTS + train_data$YOJ + train_data$TIF+
       I(train_data$MVR_PTS^2) + train_data$CLM_FREQ:train_data$MVR_PTS + train_data$CLM_FREQ:train_data$TRAVTIME_sqrt +  train_data$MVR_PTS:train_data$TRAVTIME_sqrt,
  data = train_data,
  weights = ifelse(train_data$CLM_FREQ > 2, 1.5, 1) 
)

   
# Model Summary
summary(enhanced_model)

# Model Performance on Testing Data
predictions <- predict(enhanced_model, newdata = test_data)
# Convert predictions back if log-transformed
predictions <- exp(predictions) - 1  

# Calculate Performance Metrics
mae <- mean(abs(predictions - test_data$TARGET_AMT))
mse <- mean((predictions - test_data$TARGET_AMT)^2)
rmse <- sqrt(mse)

list(MAE = mae, MSE = mse, RMSE = rmse)
```



### Summary
This model captures more complexity and explains a greater portion of the variance in TARGET_AMT_log, particularly due to added interaction terms and the significance of YOJ and TIF. However, further improvements could be explored by:

Potentially removing predictors with high p-values.
Refining interactions based on residual analysis or testing transformations on specific terms.
Overall, this model represents a notable improvement, with reduced prediction error and enhanced significance of variables contributing meaningfully to target predictions.


## Binary Logistic Regression


### Model 1

```{r}

# Set seed for reproducibility
set.seed(123)

# Split data into training and testing sets
split <- sample.split(insurance_training_data_clean$TARGET_FLAG, SplitRatio = 0.7)
train_data <- subset(insurance_training_data_clean, split == TRUE)
test_data <- subset(insurance_training_data_clean, split == FALSE)

# Build a logistic regression model with specified predictors
# Replace predictor1, predictor2, ... with actual predictor names
logistic_model1 <- glm(TARGET_FLAG ~ AGE + CAR_USE + CLM_FREQ + EDUCATION + 
                      MVR_PTS + REVOKED + TIF + TRAVTIME + URBANICITY, 
                      data = insurance_training_data_clean, family = binomial)

# Summary of the model
summary(logistic_model1)

# Predict on the test set
# Predict probabilities
prob_predictions <- predict(logistic_model1, newdata = test_data, type = "response")

# Convert probabilities to binary classes with a threshold (e.g., 0.5)
class_predictions <- ifelse(prob_predictions > 0.5, 1, 0)

# Evaluate model performance
# Confusion Matrix
confusion_matrix <- table(Predicted = class_predictions, Actual = test_data$TARGET_FLAG)
print(confusion_matrix)

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Model Accuracy:", accuracy, "\n")

```



### Model 2

```{r}
# Check for missing values
# Check for missing values
missing_values <- colSums(is.na(insurance_training_data_clean))
print(missing_values[missing_values > 0])  # Print columns with missing values

# Option 1: Remove rows with missing values
insurance_training_data_clean <- na.omit(insurance_training_data_clean)

# Option 2: Impute missing values (mean for numeric columns, mode for categorical, etc.)
# For numeric columns
numeric_cols <- sapply(insurance_training_data_clean, is.numeric)
insurance_training_data_clean[numeric_cols] <- lapply(insurance_training_data_clean[numeric_cols], 
                                                        function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))

# For categorical columns (optional, if you have any)
categorical_cols <- sapply(insurance_training_data_clean, is.factor)
insurance_training_data_clean[categorical_cols] <- lapply(insurance_training_data_clean[categorical_cols], 
                                                           function(x) ifelse(is.na(x), 
                                                                              levels(x)[which.max(table(x))], 
                                                                              x))

# Now you can fit your model again
logistic_model <- glm(TARGET_FLAG ~ AGE + CAR_USE + CLM_FREQ + EDUCATION + 
                      MVR_PTS + REVOKED + TIF + TRAVTIME + URBANICITY, 
                      data = insurance_training_data_clean, family = binomial)

# Display summary of the model
summary(logistic_model)



# Stepwise feature selection to refine predictors
logistic_model_step <- stepAIC(logistic_model, direction = "both")
summary(logistic_model_step)

# Calculate VIF
vif_values <- vif(logistic_model)
print(vif_values)

# Remove predictors with high VIF
high_vif <- names(vif_values[vif_values > 5])  # Threshold for multicollinearity
if (length(high_vif) > 0) {
  # Fit a new model excluding high VIF predictors
  reduced_model <- update(logistic_model, . ~ . - one_of(high_vif))
  summary(reduced_model)
}

# Make predictions
predictions <- predict(logistic_model_step, newdata = insurance_training_data_clean, type = "response")
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# Confusion Matrix
confusion_matrix <- table(insurance_training_data_clean$TARGET_FLAG, predicted_classes)
print(confusion_matrix)

# Accuracy, Precision, Recall
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / (confusion_matrix[2, 2] + confusion_matrix[1, 2])
recall <- confusion_matrix[2, 2] / (confusion_matrix[2, 2] + confusion_matrix[2, 1])

cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")

# ROC curve and AUC

roc_curve <- roc(insurance_training_data_clean$TARGET_FLAG, predictions)
plot(roc_curve)
cat("AUC:", auc(roc_curve), "\n")


# Create a trainControl object
control <- trainControl(method = "cv", number = 10)

# Train the model using cross-validation
cv_model <- train(TARGET_FLAG ~ ., data = insurance_training_data_clean, method = "glm", family = "binomial", trControl = control)
print(cv_model)



```
### Model 3

```{r}

# Data Cleaning: Remove rows with missing values
insurance_training_data_clean <- na.omit(insurance_training_data_clean)

# Identify numeric columns excluding TARGET_FLAG for scaling
numeric_cols <- sapply(insurance_training_data_clean, is.numeric)
numeric_cols <- names(numeric_cols[numeric_cols])  
numeric_cols <- setdiff(numeric_cols, "TARGET_FLAG") 

# Scale numeric predictors
insurance_training_data_clean[numeric_cols] <- scale(insurance_training_data_clean[numeric_cols])

# Fit a binary logistic regression model with different predictors
logistic_model <- glm(TARGET_FLAG ~ CAR_TYPE + HOME_VAL + KIDSDRIV + OLDCLAIM + SEX,
                      data = insurance_training_data_clean, family = binomial)

# Display summary of the model
summary(logistic_model)

# Optional: Stepwise feature selection
logistic_model_step <- stepAIC(logistic_model, direction = "both")
summary(logistic_model_step)

# Predictions and accuracy
predicted_probs <- predict(logistic_model, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, 1, 0)

# Create a confusion matrix
confusion_matrix <- table(insurance_training_data_clean$TARGET_FLAG, predicted_classes)
print(confusion_matrix)

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Model Accuracy:", accuracy, "\n")
```


# Select Models & Prediction

## Multiple Linear Regression Selection


### Model 5 Fit (R-Squared and Adjusted R-Squared):

R-squared: 0.09877, Adjusted R-squared: 0.09746.
Interpretation: While still modest, this R-squared value is higher than earlier models, indicating that more variance in the target variable is being explained.
Significance of Predictors:

Several predictors, including CLM_FREQ, YOJ, TIF, and I(MVR_PTS^2), as well as interactions like CLM_FREQ:MVR_PTS, are highly significant (p < 0.01).
The inclusion of YOJ (Years of Job) and TIF (Tenure in Force) has contributed significantly to model fit, likely adding valuable information about risk factors.
However, predictors like TRAVTIME_sqrt and CLM_FREQ:TRAVTIME_sqrt show higher p-values, which might indicate minimal contribution.
Residual Standard Error (RSE):

Residual standard error: 3.834 on 6160 degrees of freedom.
Interpretation: The RSE value suggests a reasonable fit, though there is room for further reduction if possible, by tuning or adjusting predictors.
Performance Metrics on Testing Data:

Mean Absolute Error (MAE): 429.8454
Mean Squared Error (MSE): 2,121,458
Root Mean Squared Error (RMSE): 1,456.523
Interpretation: This model has slightly lower MAE and RMSE than the previous one, indicating better predictive accuracy on test data.


## Binary Logistic Regression Model Selection

Model 1 stands out due to its combination of higher accuracy and the inclusion of several significant predictors, despite its higher AIC compared to Model 2. This suggests that while Model 2 fits well with fewer predictors, Model 1 provides a more comprehensive understanding of the factors influencing the target variable.

Select Model 1 for its better accuracy and significant predictors.
Consider Model 2 as a more parsimonious alternative if simplicity is preferred without a substantial loss in accuracy.

## Prediction


### Prediction Multiple Linear Regression (Model 3)
```{r}
completed_data_eval$TARGET_AMT <- mean(train_data$TARGET_AMT)
completed_data_eval$TARGET_AMT_log <- log(completed_data_eval$TARGET_AMT + 1)  # Log transformation to stabilize variance
completed_data_eval$TRAVTIME_sqrt <- sqrt(completed_data_eval$TRAVTIME)  # Square root transformation for TRAVTIME




enhanced_model <- lm(
    TARGET_AMT_log ~ completed_data_eval$CLM_FREQ + completed_data_eval$MVR_PTS + completed_data_eval$YOJ + completed_data_eval$TIF+
       I(completed_data_eval$MVR_PTS^2) + completed_data_eval$CLM_FREQ:completed_data_eval$MVR_PTS + completed_data_eval$CLM_FREQ:completed_data_eval$TRAVTIME_sqrt +  completed_data_eval$MVR_PTS:completed_data_eval$TRAVTIME_sqrt,
  data = completed_data_eval,
  weights = ifelse(completed_data_eval$CLM_FREQ > 2, 1.5, 1) 
)

#crash_data_imputed <- complete(imputed_data)
predictions <- predict(enhanced_model, newdata = completed_data_eval)
# Convert predictions back if log-transformed
predictions <- exp(predictions) - 1 
summary(enhanced_model)
# Calculate Performance Metrics
mae <- mean(abs(predictions - test_data$TARGET_AMT))
mse <- mean((predictions - test_data$TARGET_AMT)^2)
rmse <- sqrt(mse)

list(MAE = mae, MSE = mse, RMSE = rmse)


```


### Prediction Binary Logistic Regression (Model 1)

```{r}
prob_predictions <- predict(logistic_model1, newdata = insurance_evaluation_data_clean, type = "response")
class_predictions <- ifelse(prob_predictions > 0.5, 1, 0)
table(class_predictions )

```

### Conclusion

In conclusion, we explored various modeling approaches using the insurance dataset, employing both Linear Regression and Binary Logistic Regression techniques. Through a systematic process of feature engineering, variable transformation, and model selection, we developed multiple models tailored to the predictors we identified as significant. After careful evaluation of each model's performance metrics, we selected the most suitable models that demonstrated the best fit for our data. The results of these models, including key coefficients and predictive accuracy, are presented above, providing valuable insights into the factors influencing insurance outcomes. This comprehensive analysis highlights the effectiveness of our modeling strategies in understanding and predicting insurance-related variables.

-
-
-
-
-
-
-
-
-
-
-
-
-
-

# Code Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```